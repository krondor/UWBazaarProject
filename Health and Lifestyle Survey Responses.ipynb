{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Health and Lifestyle Survey Questions Tutorial\n\nIn this tutorial, we showcase how the Protodash explainer algorithm from AI Explainability 360 Toolkit implemented through the _ProtodashExplainer_ class could be used to summarize the National Health and Nutrition Examination Survey (NHANES) datasets ([Study 1](#study1)) available through the Center for Disease Control and Prevention (CDC). Moreover, we also show how the algorithm could be used to distill interesting relationships between different facets of life (i.e. early childhood and income), which were found by scientists ([Study 2](#study2)) through decades of rigorous experimentation. This study shows that in using Protodash, one can potentially uncover such insights cheaply, which could then be reaffirmed through rigorous experimentation.\n\n Data from this survey is typically used in epidemiological studies and health science research, which helps develop public health policy, direct and design health programs and services, and expand health knowledge. Thus, the impact of understanding these datasets and the relationships that may exist between them are far reaching for a social scientist."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a name=\"intro\"></a>\n## Introduction to Center for Disease Control and Prevention (CDC) datasets\n\nThe [NHANES CDC questionnaire datasets](https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Questionnaire&CycleBeginYear=2013) are surveys conducted by the organization involving thousands of civilians about various facets of their daily lives. There are 44 questionnaires that collect data about income, occupation, health, early childhood and many other behavioral and lifestyle aspects of individuals living in the US. These questionnaires are thus a rich source of information indicative of the quality of life of many civilians. \n\nThis tutorial presents two studies. We first see how a CDC questionaire answered by thousands of individuals could be summarized by looking at answers given by a few prototypical users. Next, an interesting endeavor is to uncover relationships between different aspects of life by analyzing data across the different CDC questionnaires. In the second study, we do exactly that with the help of the Protodash explainer algorithm. We show how the algorithm is able to uncover an interesting [insight](https://www.theatlantic.com/business/archive/2016/07/social-mobility-america/491240/) known only through decades of experimentation, solely from the questionnaire datasets. This by no means suggests the method as a substitute for rigorous experimentation, but showcases it as an avenue for obtaining interesting insights at low cost, which could inspire further indepth studies. The manner in which this is accomplished is by finding prototypical individuals for each of the questionnaires and then evaluating how well they represent the income questionnaire (w.r.t. the method's objective function). The more representative these prototypes are, the more that questionnaire is indicative/representative of income. \n\nFor this use case, we are selecting prototypes from specific questionnaires. Hence, the group we want to explain is the dataset itself, which \u2014 in this case \u2014 are the questionnaires. We are not training an AI model. Rather, we are trying to summarize each questionnaire, which was filled by thousands of people, by selecting a few representative individuals for each of them.\n\n\nThe rest of the tutorial is organized as follows: <br>\n[Explore Income questionaire](#explore)<br>\n[Study 1: Summarize Income Questionnaire using Prototypes](#study1)<br>\n[Study 2: Find Questionnaire/s most representative of Income](#study2)<br>\n\n\n###### [Protodash: Fast Interpretable Prototype Selection](https://arxiv.org/abs/1707.01212)\n\nWe now provide a brief overview of the method. The method takes as input a datapoint (or group of datapoints) that we want to explain with respect to instances in a training set belonging to the same feature space. The method then tries to minimize the maximum mean discrepancy (MMD metric) between the datapoints we want to explain and a prespecified number of instances from the training set that it will select. In other words, it will try to select training instances that have the same distribution as the datapoints we want to explain. The method does greedy selection and has quality guarantees with it also returning importance weights for the chosen prototypical training instances indicative of how similar/representative they are. \n\n\n###### Why Protodash?\n\nBefore we showcase the two studies, we provide some motivation for using this method. The method is able to select in a deterministic fashion examples from a dataset, which we term as prototypes that represent the different segments in a dataset. For example, if we take people that answered the income questionnaire, we might find that there are three categories of people: i) those that are high earners, ii) those that are middle class and iii) those that don't earn much or are unemployed and receive unemployment benefits. Protodash would be able to find these segments by pointing to specific individuals that lie in these categories. Looking at the objective function value of Protodash, one would also be able to say that three segments is the right number here as adding one more segment may not improve the objective value by much.\n\nCompared with other methods such as k-medoids, it has the advantage that it is deterministic and does not have randomizations as in, say, k-medoids clustering, where the centers a typically randomly initialized. So the solutions are repeatable and it picks prototypes that are representative as well as diverse, which may not be the case with standard distance metrics such as euclidean distance. Diversity is important in practical settings (viz. income example above) where we want to capture all the different segments/modes in the dataset, not missing any of the key behaviors.\n\nAnother benefit of the method is that, since it performs distribution matching between the user/users in question and those available in the training set, it could, in principle, also be applied in non-iid settings such as for time series data. Other approaches which find similar profiles using standard distance measures (viz. euclidean, cosine) do not have this property. Additionally, we can also highlight important features for the different prototypes that made them similar to the user/users in question."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Import Statements\n\nImport relevant libraries, datasets and Protodash explainer algorithm."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "!pip install aix360"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport requests\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom aix360.algorithms.protodash import ProtodashExplainer\nfrom aix360.datasets.cdc_dataset import CDCDataset"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Load CDC dataset"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "nhanes = CDCDataset()\nnhanes_files = nhanes.get_csv_file_names()\n(nhanesinfo, _, _) = nhanes._cdc_files_info()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a name=\"explore\"></a>\n## Explore Income questionnaire\n\nNow let us explore the income questionnaire dataset and find out the types of responses received in the survey. Each column in the dataset corresponds to a question and each row denotes the answers given by a respondent to those questions. Both column names and answers by respondents are encoded. For example, 'SEQN' denotes the sequence number assigned to a respondent and 'IND235' corresponds to a question about monthly family income. As seen below, in most cases a value of 1 implies \"Yes\" to the question, while a value of 2 implies \"No.\" More details about the income questionaire and how questions and answers are encoded can be seen [here](https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/INQ_H.htm)\n\n|Column  |Description                    | Values and Meaning|\n|-------|----------------------------|---------|\n|SEQN   | Respondent sequence number |\n|INQ020 | Income from wages/salaries |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|INQ012 | Income from self employment|1->Yes, 2->No, 7->Refused, 9->Don't know|\n|INQ030 | Income from Social Security or RR |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|INQ060 | Income from other disability pension |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|INQ080 | Income from retirement/survivor pension |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|INQ090 | Income from Supplemental Security Income |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|INQ132 | Income from state/county cash assistance |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|INQ140 | Income from interest/dividends or rental |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|INQ150 | Income from other sources |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|IND235 | Monthly family income |1-12->Increasing income brackets, 77->Refused, 99->Don't know|\n|INDFMMPI | Family monthly poverty level index |0-5->Higher value more affluent|\n|INDFMMPC | Family monthly poverty level category |1-3->Increasing INDFMMPI brackets, 7->Refused, 9->Don't know|\n|INQ244 | Family has savings more than $5000 |1->Yes, 2->No, 7->Refused, 9->Don't know|\n|IND247 | Total savings/cash assets for the family |1-6->Increasing savings brackets, 77->Refused, 99->Don't know|"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# replace encoded column names by the associated question text. \ndf_inc = nhanes.get_csv_file('INQ_H.csv')\ndf_inc.columns[0]\ndict_inc = {\n'SEQN': 'Respondent sequence number', \n'INQ020': 'Income from wages/salaries',\n'INQ012': 'Income from self employment',\n'INQ030':'Income from Social Security or RR',\n'INQ060':  'Income from other disability pension', \n'INQ080':  'Income from retirement/survivor pension',\n'INQ090':  'Income from Supplemental Security Income',\n'INQ132':  'Income from state/county cash assistance', \n'INQ140':  'Income from interest/dividends or rental', \n'INQ150':  'Income from other sources',\n'IND235':  'Monthly family income',\n'INDFMMPI':  'Family monthly poverty level index', \n'INDFMMPC':  'Family monthly poverty level category',\n'INQ244':  'Family has savings more than $5000',\n'IND247':  'Total savings/cash assets for the family'\n}\nqlist = []\nfor i in range(len(df_inc.columns)):\n    qlist.append(dict_inc[df_inc.columns[i]])\ndf_inc.columns = qlist\nprint(\"Answers given by some respondents to the income questionnaire:\")\ndf_inc.head(5).transpose()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, to get more of a feel for the dataset, let us look at the distribution of responses for two questions related to family financial status."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(\"Number of respondents to Income questionnaire:\", df_inc.shape[0])\nprint(\"Distribution of answers to \\'monthly family income\\' and \\'Family savings\\' questions:\")\n\nfig, axes = plt.subplots(1, 2, figsize=(10,5))\nfig.subplots_adjust(wspace=0.5)\nhist1 = df_inc['Monthly family income'].value_counts().plot(kind='bar', ax=axes[0])\nhist2 = df_inc['Family has savings more than $5000'].value_counts().plot(kind='bar', ax=axes[1])\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a name=\"Dplot\"></a>\nObserve that the majority of individuals responded with a \"12\" o the question related to monthly family income, which means their income is above USD 8400 as explained [here](https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/INQ_H.htm#IND235). Similarly, to the question of whether the family has savings more than USD 5000, the majority of individuals responded with a \"2\", which means \"No\". "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a name=\"study1\"></a>\n## Study 1: Summarize Income Questionnaire using Prototypes\n\nWe just explored the income dataset and looked at the distribution of answers for a couple of questions. Now, consider a social scientist who would like to quickly obtain a summary report of this dataset in terms of types of people that span this dataset. Is it possible to summarize this dataset by looking at answers given by a few representative/prototypical respondents? \n\nWe now show how the Protodash algorithm can be used to obtain a few prototypical respondents (about 10 in this example) that span the diverse set of individuals answering the income questionnaire making it easy for the social scientist to summarize the dataset."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# convert pandas dataframe to numpy\ndata = df_inc.to_numpy()\n\n#sort the rows by sequence numbers in 1st column \nidx = np.argsort(data[:, 0])  \ndata = data[idx, :]\n\n# replace nan's (missing values) with 0's\noriginal = data\noriginal[np.isnan(original)] = 0\n\n# delete 1st column (sequence numbers)\noriginal = original[:, 1:]\n\n# one hot encode all features as they are categorical\nonehot_encoder = OneHotEncoder(sparse=False)\nonehot_encoded = onehot_encoder.fit_transform(original)\n\nexplainer = ProtodashExplainer()\n\n# call Protodash explainer\n# S contains indices of the selected prototypes\n# W contains importance weights associated with the selected prototypes \n(W, S, _) = explainer.explain(onehot_encoded, onehot_encoded, m=10) \n\n# sort the order of prototypes in set S\nidx = np.argsort(S)\nS = S[idx]\nW = W[idx]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Display the prototypes along with their computed weights\ninc_prototypes = df_inc.iloc[S, :].copy()\n# Compute normalized importance weights for prototypes\ninc_prototypes[\"Weights of Prototypes\"] = np.around(W/np.sum(W), 2) \ninc_prototypes.transpose()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Explanation:\nThe 10 people shown above (i.e. 10 prototypes) are representative of the income questionnaire according to Protodash. Firstly, in the distribution plot for family finance related questions, we saw that there roughly were five times as many people not having savings in excess of $5000 compared with others. Our prototypes also have a similar spread, which is reassuring. Also, for monthly family income, we get a more even spread over the more commonly occurring categories. This is a kind of spot check to see if our prototypes actually match the distribution of values in the dataset.\n\nLooking at the other questions in the questionnaire and the corresponding answers given by the prototypical people above, the social scientist realizes that most people are employed (3rd question) and work for an organization earning through salary/wages (1st two questions). Most of them are also young (5th question) and fit to work (4th question). However, they don't seem to have much savings (last question). The insights that the social scientist acquired from studying the prototypes could also be conveyed to the appropriate government authorities that affect future public policy decisions."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a name=\"study2\"></a>\n## Study 2: Find Questionnaire/s that are most representative of Income\n\nWe now move on to our second study, where we want to see how the remaining 39 questionnaires represent or relate to income. This will provide us with an idea of which lifestyle factors are likely to affect income the most. To do this we compute prototypes for each of the questionnaires and evaluate how well they represent the income questionnaire relative to our objective function. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Compute prototypes for all questionaires\n\nThis step uses Protodash explainer to compute 10 prototypes for each of the questionaires and saves these for  further evaluation. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Iterate through all questionnaire datasets and find 10 prototypes for each.\n\nprototypes = {}\n\nfor i in range(len(nhanes_files)):\n    \n    f = nhanes_files[i]\n    \n    print(\"processing \", f)\n    \n    # read data to pandas dataframe\n    df = nhanes.get_csv_file(f)\n    \n    # convert data to numpy\n    data = df.to_numpy()\n\n    #sort the rows by sequence numbers in 1st column \n    idx = np.argsort(data[:, 0])\n    data = data[idx, :]\n\n    # replace nan's with 0's.\n    original = data\n    original[np.isnan(original)] = 0\n\n    # delete 1st column (contains sequence numbers)\n    original = original[:, 1:]\n\n    # one hot encode all features as they are categorical\n    onehot_encoder = OneHotEncoder(sparse=False)\n    onehot_encoded = onehot_encoder.fit_transform(original)\n\n    explainer = ProtodashExplainer()\n\n    # call Protodash explainer\n    # S contains indices of the selected prototypes\n    # W contains importance weights associated with the selected prototypes \n\n    (W, S, _) = explainer.explain(onehot_encoded, onehot_encoded, m=10) \n\n    prototypes[f]={}\n    prototypes[f]['W']= W\n    prototypes[f]['S']= S\n    prototypes[f]['data'] = data\n    prototypes[f]['original'] = original"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Evaluate the set of prototypical respondents from various questionaires using their income questionaire. \n\nNow that we have the prototypes for each of the questionnaires we evaluate how well the prototypes of each questionaire represent the Income questionnaire based on the objective function that Protodash uses. We see below a ranked list of different questionnaires with their objective function values in ascending order. The higher a questionaire appears in the list, the better its prototypes represent the income questionaire. The values on the right indicate our objective value where lower value is better."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#load income dataset INQ_H and its prototypes\nX = prototypes['INQ_H.csv']['original']\nXdata = prototypes['INQ_H.csv']['data']\n\n# Iterate through all questionnaires and evaluate how well their prototypes represent the income dataset. \nobjs = []\nfor i in range(len(nhanes_files)):\n        \n    #load a dataset, its prototypes & weights\n\n    f = nhanes_files[i]\n    \n    Ydata = prototypes[f]['data']\n    S = prototypes[f]['S']\n    W = prototypes[f]['W']\n    \n    \n    # sort the order of prototypes in set S\n    idx = np.argsort(S)\n    S = S[idx]\n    W = W[idx]\n    \n    # access corresponding prototypes in X. \n    XS = X[np.isin(Xdata[:, 0], Ydata[S, 0]), :]\n    \n    #print(Ydata[S, 0])\n    #print(Xdata[np.isin(Xdata[:, 0], Ydata[S, 0]), 0])   \n    \n    temp = np.dot(XS, np.transpose(X))    \n    u = np.sum(temp, axis=1)/temp.shape[1]\n    \n    K = np.dot(XS, XS.T)\n    \n    # evaluate prototypes on income based on our objective function with dot product as similarity measure\n    obj = 0.5 * np.dot(np.dot(W.T, K), W) - np.dot(W.T, u)\n    objs.append(obj)    \n    \n\n# sort the objectives (ascending order) \nindex = np.argsort(np.array(objs))\n\n# load the results in a dataframe to print\nevalresult = []\nfor i in range(0,len(index)):    \n    evalresult.append([ nhanesinfo[index[i]], objs[index[i]] ])\n    \n    \ndf_evalresult = pd.DataFrame.from_records(evalresult)\ndf_evalresult.columns = ['Questionaire', 'Prototypes representative of Income']\ndf_evalresult"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Insight from Protodash\n\nLooking at the table above, what is interesting is that early childhood represents income the most. The early childhood questionnaire has information about the environment that the child was born and raised in. This is consistent with a long term study (https://www.theatlantic.com/business/archive/2016/07/social-mobility-america/491240/) which talks about significant decrease in social mobility in recent times, stressing the fact that your childhood impacts how monetarily successful you are likely to be. It is interesting that our method was able to uncover this relationship with access to just these survey questionnaires. Other such insights could be obtained and ones that a social scientist or policy maker finds interesting could potentially spawn long-term studies like the one just mentioned."
        }
    ],
    "metadata": {
        "celltoolbar": "Edit Metadata",
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}